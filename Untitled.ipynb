{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b29909-9818-4f8c-bad8-01c5d7b49364",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-20 13:23:42] Logger OK\n"
     ]
    }
   ],
   "source": [
    "import importlib, process_logger as pl\n",
    "importlib.reload(pl)\n",
    "from process_logger import log as process_log\n",
    "process_log(\"Logger OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b450aa-251f-4b78-b061-3354257215ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for _LLMConfig\nconfig_list.0.openai.model\n  Input should be a valid string [type=string_type, input_value={'provider': 'google', 'm...cation': 'us-central1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nconfig_list.0.openai.role_name\n  Extra inputs are not permitted [type=extra_forbidden, input_value='Causal Analyst', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversableAgent, UserProxyAgent\n\u001b[32m     11\u001b[39m llm_cfg = {\n\u001b[32m     12\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mrole_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCausal Analyst\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m   }\n\u001b[32m     22\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m g = \u001b[43mConversableAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini_test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m u = UserProxyAgent(\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, human_input_mode=\u001b[33m\"\u001b[39m\u001b[33mNEVER\u001b[39m\u001b[33m\"\u001b[39m, max_consecutive_auto_reply=\u001b[32m1\u001b[39m)\n\u001b[32m     25\u001b[39m u.initiate_chat(g, message=\u001b[33m\"\u001b[39m\u001b[33mPowiedz jedno zdanie o mechanice kwantowej.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/agents_with_memory_py11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:262\u001b[39m, in \u001b[36mConversableAgent.__init__\u001b[39m\u001b[34m(self, name, system_message, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, llm_config, default_auto_reply, description, chat_messages, silent, context_variables, functions, update_agent_state_before_reply, handoffs)\u001b[39m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    257\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    258\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease implement __deepcopy__ method for each value class in llm_config to support deepcopy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    259\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Refer to the docs for more details: https://docs.ag2.ai/docs/user-guide/advanced-concepts/llm-configuration-deep-dive/#adding-http-client-in-llm_config-for-proxy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_config = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_llm_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[38;5;28mself\u001b[39m._create_client(\u001b[38;5;28mself\u001b[39m.llm_config)\n\u001b[32m    264\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_name(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/agents_with_memory_py11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:498\u001b[39m, in \u001b[36mConversableAgent._validate_llm_config\u001b[39m\u001b[34m(cls, llm_config)\u001b[39m\n\u001b[32m    496\u001b[39m         llm_config = \u001b[38;5;28mcls\u001b[39m.DEFAULT_CONFIG\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m     llm_config = \u001b[43mLLMConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm_config, LLMConfig):\n\u001b[32m    500\u001b[39m     llm_config = llm_config.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/agents_with_memory_py11/lib/python3.11/site-packages/autogen/llm_config.py:84\u001b[39m, in \u001b[36mLLMConfig.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m         modified_kwargs[\u001b[33m\"\u001b[39m\u001b[33mconfig_list\u001b[39m\u001b[33m\"\u001b[39m] = [{**v, x: modified_kwargs[x]} \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m modified_kwargs[\u001b[33m\"\u001b[39m\u001b[33mconfig_list\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m     82\u001b[39m         modified_kwargs.pop(x)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[38;5;28mself\u001b[39m._model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_base_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodified_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/agents_with_memory_py11/lib/python3.11/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 2 validation errors for _LLMConfig\nconfig_list.0.openai.model\n  Input should be a valid string [type=string_type, input_value={'provider': 'google', 'm...cation': 'us-central1'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nconfig_list.0.openai.role_name\n  Extra inputs are not permitted [type=extra_forbidden, input_value='Causal Analyst', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden"
     ]
    }
   ],
   "source": [
    "from autogen_orchestrator import AutoGenMOAOrchestrator\n",
    "from autogen import ConversableAgent\n",
    "from config_api import *\n",
    "import autogen\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from autogen import ConversableAgent, UserProxyAgent\n",
    "llm_cfg = {\n",
    "  \"role_name\": \"Causal Analyst\",\n",
    "  \"model\": {\n",
    "    \"provider\": \"google\",\n",
    "    \"model_name\": \"gemini-2.5-pro\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"client_args\": {\n",
    "      \"vertex_project\": \"dark-data-discovery\",\n",
    "      \"vertex_location\": \"us-central1\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "g = ConversableAgent(\"gemini_test\", llm_config=llm_cfg)\n",
    "u = UserProxyAgent(\"user\", human_input_mode=\"NEVER\", max_consecutive_auto_reply=1)\n",
    "u.initiate_chat(g, message=\"Powiedz jedno zdanie o mechanice kwantowej.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdcf709-087a-49f8-be19-df05c0dc018f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "def spakuj_biezacy_folder(nazwa_pliku_zip=None):\n",
    "    \"\"\"\n",
    "    Pakuje cały bieżący folder roboczy (wraz z podfolderami) do pliku ZIP.\n",
    "    Archiwum ZIP jest tworzone w folderze nadrzędnym, aby uniknąć\n",
    "    dodania samego siebie do archiwum.\n",
    "\n",
    "    Args:\n",
    "        nazwa_pliku_zip (str, optional): Opcjonalna nazwa dla pliku ZIP (bez rozszerzenia .zip).\n",
    "                                        Jeśli nie zostanie podana, nazwa zostanie wygenerowana\n",
    "                                        automatycznie na podstawie nazwy folderu i aktualnej daty.\n",
    "\n",
    "    Returns:\n",
    "        str: Pełna ścieżka do utworzonego pliku ZIP lub None w przypadku błędu.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Pobierz pełną ścieżkę do bieżącego folderu\n",
    "        biezacy_folder = os.getcwd()\n",
    "        \n",
    "        # Uzyskaj nazwę bieżącego folderu\n",
    "        nazwa_folderu = os.path.basename(biezacy_folder)\n",
    "\n",
    "        # Ustal nazwę pliku wyjściowego\n",
    "        if nazwa_pliku_zip is None:\n",
    "            # Wygeneruj domyślną nazwę, jeśli nie podano własnej\n",
    "            znacznik_czasu = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            nazwa_pliku_zip = f\"{nazwa_folderu}_{znacznik_czasu}\"\n",
    "        \n",
    "        # Dodaj rozszerzenie .zip, jeśli go brakuje\n",
    "        if not nazwa_pliku_zip.endswith('.zip'):\n",
    "            nazwa_pliku_zip += '.zip'\n",
    "            \n",
    "        # Utwórz plik ZIP w folderze nadrzędnym, aby uniknąć rekursji\n",
    "        folder_nadrzedny = os.path.dirname(biezacy_folder)\n",
    "        sciezka_do_zipa = os.path.join(folder_nadrzedny, nazwa_pliku_zip)\n",
    "\n",
    "        print(f\"Tworzenie archiwum: {sciezka_do_zipa}\")\n",
    "\n",
    "        # Otwórz plik ZIP do zapisu\n",
    "        with zipfile.ZipFile(sciezka_do_zipa, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # Przejdź przez wszystkie pliki i foldery w bieżącym katalogu\n",
    "            for root, dirs, files in os.walk(biezacy_folder):\n",
    "                for file in files:\n",
    "                    # Stwórz pełną ścieżkę do pliku\n",
    "                    sciezka_pliku = os.path.join(root, file)\n",
    "                    # Oblicz ścieżkę względną, aby zachować strukturę folderów w ZIPie\n",
    "                    sciezka_w_archiwum = os.path.relpath(sciezka_pliku, biezacy_folder)\n",
    "                    # Zapisz plik do archiwum\n",
    "                    zipf.write(sciezka_pliku, sciezka_w_archiwum)\n",
    "\n",
    "        print(\"Archiwum zostało pomyślnie utworzone!\")\n",
    "        return sciezka_do_zipa\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Wystąpił błąd podczas tworzenia archiwum: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61302904-78f5-4fc2-8458-dfb5d817fe28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tworzenie archiwum: /home/jupyter/olga_zydziak/version_beta/moa_debate_20250822_001008.zip\n",
      "Archiwum zostało pomyślnie utworzone!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/olga_zydziak/version_beta/moa_debate_20250822_001008.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spakuj_biezacy_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c15b0f-542a-4025-9964-c6f7c5bad756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "agents_with_memory_p11",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Agents with memory (Python 3.11)",
   "language": "python",
   "name": "agents_with_memory_p11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
